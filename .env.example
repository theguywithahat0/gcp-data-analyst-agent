# Copy as .env file and fill your values below
# Run ./update_dotenv_example.sh to update .env-example from your .env file.

# Required Environment Variables - Use your existing infrastructure
# Use Vertex AI instead of Google AI Studio API
GOOGLE_GENAI_USE_VERTEXAI=1
GOOGLE_CLOUD_PROJECT=YOUR_EXISTING_PROJECT_ID
BQ_DATASET_ID=YOUR_EXISTING_DATASET_ID

# Model Configuration (using Gemini 2.5 Flash)
ROOT_AGENT_MODEL=gemini-2.5-flash
DATA_ANALYST_AGENT_MODEL=gemini-2.5-flash
BIGQUERY_AGENT_MODEL=gemini-2.5-flash
ANALYTICS_AGENT_MODEL=gemini-2.5-flash
BQML_AGENT_MODEL=gemini-2.5-flash

# RAG Configuration - Use your existing RAG corpora
# General business/domain knowledge RAG corpus
RAG_CORPUS=YOUR_EXISTING_RAG_CORPUS
# BQML-specific documentation and examples RAG corpus  
BQML_RAG_CORPUS_NAME=YOUR_EXISTING_BQML_RAG_CORPUS

# Google Cloud Configuration - Use your existing setup
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_CLOUD_STORAGE_BUCKET=YOUR_EXISTING_STORAGE_BUCKET

# Code Interpreter Configuration (optional) - Use your existing extension
CODE_INTERPRETER_EXTENSION_NAME=YOUR_EXISTING_CODE_INTERPRETER_EXTENSION

# SQLGen method 
NL2SQL_METHOD="BASELINE" # BASELINE or CHASE

# Legacy compatibility - these will be mapped to the above values
BQ_PROJECT_ID=${GOOGLE_CLOUD_PROJECT}
BASELINE_NL2SQL_MODEL=${ROOT_AGENT_MODEL}
CHASE_NL2SQL_MODEL=${ROOT_AGENT_MODEL}

# RAG Embedding Configuration
RAG_EMBEDDING_MODEL=text-embedding-005
RAG_CORPUS_DISPLAY_NAME=your_corpus_display_name
RAG_DATA_SOURCE_PATH=gs://your-bucket/path/to/data

# RAG Chunking Configuration
RAG_CHUNK_SIZE=512
RAG_CHUNK_OVERLAP=100
RAG_MAX_EMBEDDING_REQUESTS_PER_MIN=1000

# RAG Retrieval Configuration
RAG_TOP_K=3
RAG_VECTOR_DISTANCE_THRESHOLD=0.5 